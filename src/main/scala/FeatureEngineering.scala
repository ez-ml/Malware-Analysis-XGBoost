package ezml
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.feature.{CountVectorizer, RegexTokenizer, StopWordsRemover, VectorAssembler}
import org.apache.spark.sql.{DataFrame, SparkSession}

object FeatureEngineering {


  def main(args: Array[String]): Unit = {

    val spark = SparkSession
      .builder()
      .appName("MalwareAnalysisXGBoost_11")
      .enableHiveSupport()
      .getOrCreate()

    val sc=spark.sparkContext


    import spark.implicits._
    import spark.sql


    val temp_df=spark.sql("select * from malware_tmp_1").repartition(2000)

    def featureEngineeringCountF(spark: SparkSession,dataMatrix: DataFrame): DataFrame ={

      val tokenizer = new RegexTokenizer().setInputCol("RawText").setOutputCol("wordsArray")
      val remover = new StopWordsRemover().setInputCol("wordsArray").setOutputCol("filteredWords")
      val cnt = new  CountVectorizer().setInputCol("filteredWords").setOutputCol("countv").setVocabSize(20)
      val assembler = new VectorAssembler().setInputCols(Array("countv")).setOutputCol("features")
      val pipeline = new Pipeline().setStages(Array(tokenizer, remover, cnt, assembler))
      val model= pipeline.fit(dataMatrix)
      model.transform(dataMatrix).drop("RawText","wordsArray","filteredWords")


    }

    val final_df = featureEngineeringCountF(spark,temp_df).repartition(200)

    final_df.cache()

    final_df.write.mode("overwrite").format("parquet").option("compression","snappy").saveAsTable("malware_tmp_2")

  }


}
